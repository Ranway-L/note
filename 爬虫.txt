#Request库入门
	
	#Request库的七个主要方法
	requests.request()
	requests.get()
	requests.head()
	requests.post()
	requests.put()
	requests.patch()  局部修改请求	
	requests.delete()
	
	
	r = requests.get(url)
	构造一个向服务器请求资源的Request对象（Request库内部生成）
	返回的内容用变量r表示，是一个Response对象，包含从服务器返回的所有相关资源
	
	requests.get(url,params=None,**kwargs)
	
	#Response对象的属性
		r.status_code HTTP请求的返回状态，200为成功，非200为失败
		r.text HTTP响应内容的字符串形式，即，url对应的编码内容
		r.encoding 从HTTP header中猜测出来的编码方式
		r.apparent_encoding 从内容中分析出的响应内容编码方式（备选编码方式）（往往更加准确）
		r.content HTTP响应内容的二进制形式
		
	#Requests库的异常
		requests.ConnectionError 网络连接错误异常，如DNS查询失败、拒绝连接等
		requests.HTTPError HTTP错误异常
		requests.URLRequired URL缺失异常
		requests.TooManyRedirects 超过最大重定向次数，产生重定向异常
		requests.ConnectTimeout 连接远程服务器超时异常
		requests.Timeout 请求URL超时，产生超时异常
		
	r.raise_for_status() 如果不是200，产生异常requests.HTTPError
	
	#爬取网页的通用代码框架
	def getHTMLText(url):
		try:
			r = requests.get(url,timeout = 30)
			r.raise_for_status()
			r.encoding = r.apparent_encoding
			return r.text
		except:
			return"产生异常"
			
			
	#HTTP协议
		URL格式 http://host[:port][path]
		host:合法的Internet主机域名或IP地址
		port：端口号，缺省端口为80
		path：请求资源的路径
		
#网络爬虫规则：
	Robots协议
	/robots.txt
	#注释，*代表所有，/代表根目录
	User-agent:*
	Disallow:/
	
#伪装浏览器进行爬虫访问
	修改头部字段
	kv = {'user-agent':'Mozilla/5.0'}
	r = requests.get(url,headers=kv)
	
#百度搜索全代码
	import requests
	keyword = 'python'
	try:
		kv = {'wd':keyword}
		r = r.requests.get("http://www.baidu.com/s" ,params=kv)
		print(r.requests.url)
		r.raise_for_status()
		print(len(r.text))
	except:
		print("爬取失败")
		
		//360搜索将键值由wd改为q

#图片爬取全代码
	import os
	import requests
	url = "http://afafafa.com/1321311313.jpg"
	root = "D://pics//"
	path = root + url.split('/')[-1]
	try:
		if not os.path.exists(root):
			os.mkdir(root)
		if not os.path.exists(path):
			r = requests.get(url)
			with open(path,'wb') as f:
				f.write(r.conten)
				f.close()
				print("文件保存成功")
	except:
		print("爬取失败")